# -*- coding: utf-8 -*-
"""Mixed-type Wafer Defect.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EkrRrx_PrArx4BuS7sZceWT1OiLAztDf
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("co1d7era/mixedtype-wafer-defect-datasets")

print("Path to dataset files:", path)

import os

from google.colab import files

pdf_path = os.path.join(path, 'E.pdf')
files.download(pdf_path)  # Downloads the PDF file to your computer

import os
import numpy as np

 # Load the .npz file
file_path = os.path.join(path, 'Wafer_Map_Datasets.npz')

data = np.load(file_path)

 # Check the keys in the .npz file
print("Keys in the dataset:", data.files)

 # Inspect the first key's data
for key in data.files:
     print(f"Data for key '{key}':", data[key])
     break  # View just the first key to avoid overload

import matplotlib.pyplot as plt
import numpy as np

# Load the .npz file
file_path = os.path.join(path, 'Wafer_Map_Datasets.npz')
data = np.load(file_path)

# Check each array to see if it's an image
for key in data.files:
    array = data[key]
    print(f"Key: {key}, Shape: {array.shape}, Dtype: {array.dtype}")

                # Check if it's likely an image
    if len(array.shape) in [2, 3]:  # 2D (grayscale) or 3D (RGB)
       print(f"Array '{key}' might be an image. Displaying a sample...")

                                    # Display the first image
       plt.imshow(array[0], cmap='gray' if array.ndim == 2 else None)
       plt.title(f"Sample from '{key}'")
       plt.show()
       break

images = data['arr_0']
print(f"Shape of images: {images.shape}")

labels = data['arr_1']

# Check the shapes of images and labels
print(f"Shape of images: {images.shape}")
print(f"Shape of labels: {labels.shape}")

print(images[0])
plt.figure(figsize=(10,10))
plt.imshow(images[0])

from sklearn.model_selection import train_test_split

# Split data into training, validation, and test sets
x_train, x_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

print(f"Training set: {x_train.shape}, Validation set: {x_val.shape}, Test set: {x_test.shape}")

print(x_train[26609].shape)

type(x_train)

print(labels[0])

import torch

# Assuming x_train, x_val, x_test are your NumPy arrays
x_train_tensor = torch.from_numpy(x_train)
x_val_tensor = torch.from_numpy(x_val)
x_test_tensor = torch.from_numpy(x_test)

# Do the same for your labels (y_train, y_val, y_test)
y_train_tensor = torch.from_numpy(y_train)
y_val_tensor = torch.from_numpy(y_val)
y_test_tensor = torch.from_numpy(y_test)

y_test_tensor.shape

y_test_integers = torch.argmax(y_test_tensor, dim=1)

y_valid_integers = torch.argmax(y_val_tensor, dim=1)

type(x_train_tensor)

y_train_tensor.shape

y_train_integers = torch.argmax(y_train_tensor, dim=1)

y_train_integers.shape

import torch
import torch.nn as nn

import torch.nn as nn

import torch.nn as nn

class OneConv(nn.Module):
    def __init__(self):
        super(OneConv, self).__init__()

        # Convolutional layers
        self.conv = nn.Conv2d(in_channels=1, out_channels=9, kernel_size=(5, 5))
        self.flatten = nn.Flatten()
        # The output of the convolutional layer is 9 channels, 48x48 (52 input - 5 kernel + 1 padding on each side = 48)
        # So the flattened size is 9 * 48 * 48
        self.fc = nn.Linear(9 * 48 * 48, 8)  # Output size is 8

    def forward(self, x):
        # Pass through convolutional layers
        x = nn.functional.relu(self.conv(x))

        # Flatten the output from convolutional layers
        x = self.flatten(x)

        # Pass through fully connected layers
        x = nn.functional.log_softmax(self.fc(x), dim=1)
        return x

!pip install torchviz

from torchviz import make_dot
import torch

net = OneConv()

dummy_input = torch.randn( 1,1, 52, 52)

output=net(dummy_input)

dot = make_dot(output, params=dict(net.named_parameters()))

dot.format = "svg"  # Set the format to SVG for inline display
display(dot)  # Directly render in the Colab notebook

import torch.optim as optim

model = OneConv()
loss_function = nn.NLLLoss()  # Negative Log-Likelihood Loss
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Training loop
epochs = 100
for epoch in range(epochs):
    # Forward pass
    # Reshape x_train_tensor to have 1 channel
    y_pred = model(x_train_tensor.float().unsqueeze(1))  # Add channel dimension
    # Compute loss
    loss = loss_function(y_pred, y_train_integers)
    # Backward pass
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')

test_loss = 0
correct = 0
total = 0

y_test_integers.shape

with torch.no_grad():
    for i in range(len(x_test_tensor)):  # Iterate over the length of the test set
        # Forward pass: Get predictions from the model
        # Correctly reshape to [batch_size, channels, height, width] which is [1, 1, 52, 52]
        pred = model(x_test_tensor[i].float().unsqueeze(0).unsqueeze(0))
        # Calculate the loss
        loss = loss_function(pred, y_test_integers[i].unsqueeze(0)).item() # Add an extra dimension to labels
        test_loss += loss  # Accumulate the loss

        # Get the predicted class labels
        _, predicted = torch.max(pred, 1)  # pred contains raw output (logits), so we use torch.max to get the predicted class index

        # Calculate the number of correct predictions
        total += 1  # Increment total by 1 for each sample
        correct += (predicted == y_test_integers[i]).sum().item()  # Compare with the correct label

    # Calculate the average test loss
    average_test_loss = test_loss / len(x_test_tensor)

    # Calculate the accuracy
    accuracy = 100 * correct / total

    print(f'Average Test Loss: {average_test_loss:.4f}')
    print(f'Accuracy: {accuracy:.2f}%')

val_loss = 0
correct = 0
total = 0

with torch.no_grad():
    for i in range(len(x_val_tensor)):  # Iterate over the length of the test set
        # Forward pass: Get predictions from the model
        # Correctly reshape to [batch_size, channels, height, width] which is [1, 1, 52, 52]
        pred = model(x_val_tensor[i].float().unsqueeze(0).unsqueeze(0))
        # Calculate the loss
        loss = loss_function(pred, y_valid_integers[i].unsqueeze(0)).item() # Add an extra dimension to labels
        val_loss += loss  # Accumulate the loss

        # Get the predicted class labels
        _, predicted = torch.max(pred, 1)  # pred contains raw output (logits), so we use torch.max to get the predicted class index

        # Calculate the number of correct predictions
        total += 1  # Increment total by 1 for each sample
        correct += (predicted == y_valid_integers[i]).sum().item()  # Compare with the correct label

    # Calculate the average test loss
    average_val_loss = val_loss / len(x_val_tensor)

    # Calculate the accuracy
    accuracy = 100 * correct / total

    print(f'Average Val Loss: {average_val_loss:.4f}')
    print(f'Accuracy: {accuracy:.2f}%')